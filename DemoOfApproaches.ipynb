{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "from numpy import nan\n",
    "import math\n",
    "import itertools\n",
    "import ProbGraphGenerator as pg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Properties of the Aggregation Process</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Theoretical Properties of Aggregation Function</h3>\n",
    "\n",
    "<ol>\n",
    "<li>Always expect some sort of output</li>\n",
    "<li>If same set of probabiltistic frameworks are inserted we expect the result to be equal to one of the inputs</li>\n",
    "<li>If one graph is input then we expect the same graph to come out</li>\n",
    "<li>Symmetrical, so that order of aggregation does not matter</li>\n",
    "<li>Mixture thing</li>\n",
    "<li>Minimal distance between two probability distributions is minimal</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Theoretical Properties of Query Function</h3>\n",
    "\n",
    "<ol>\n",
    "\n",
    "<li>If we have a query agent, who is querying a set of probabilistic graphs who have the same set of arguments, then we expect the result to be the proportion of the net positives/negatives/neutrals</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select List of Negative and Positive Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "textPos = widgets.Text(description='List of Positive Arguments', width=500)\n",
    "textNeg = widgets.Text(description='List of Negative Arguments', width=500)\n",
    "display(textPos)\n",
    "display(textNeg)\n",
    "\n",
    "# list of user provided args\n",
    "posArgs = []\n",
    "negArgs = []\n",
    "\n",
    "def handle_submit(sender):\n",
    "    if sender == textPos:\n",
    "        splitlist = (textPos.value).split(\",\")\n",
    "        args = [int(a) for a in splitlist]\n",
    "        posArgs.extend(args)\n",
    "    if sender == textNeg:\n",
    "        splitlist = (textNeg.value).split(\",\")\n",
    "        args = [int(a) for a in splitlist]\n",
    "        negArgs.extend(args)\n",
    "        \n",
    "    print(posArgs)\n",
    "    print(negArgs)\n",
    "\n",
    "    \n",
    "textPos.on_submit(handle_submit)\n",
    "textNeg.on_submit(handle_submit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allAgents = []\n",
    "\n",
    "textAgent = widgets.Text(description='Insert an Agent', width=500)\n",
    "display(textAgent)\n",
    "\n",
    "\n",
    "\n",
    "def handle_new_agent(sender):\n",
    "    \n",
    "    splitlist = (textAgent.value).split(\",\")\n",
    "    agentArgs = [int(a) for a in splitlist[0:-1]]\n",
    "    agentTotals = []\n",
    "    posFound = list(set(agentArgs).intersection(posArgs))\n",
    "    negFound = list(set(agentArgs).intersection(negArgs))\n",
    "    polarity = splitlist[-1]\n",
    "    print(posFound)\n",
    "    agentTotals = (posFound,negFound, polarity)\n",
    "    \n",
    "    allAgents.append(agentTotals)\n",
    "    \n",
    "textAgent.on_submit(handle_new_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAgents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing Different Aggregation Approaches</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-7d0f9e8cf9c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgraphDistribs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Not needed when we have the graphDistribsGlobal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0meveryGraphProduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerateGraphsGivenSetsOfArgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposArgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegArgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mgraphDistribsGlobal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprobDistribs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Robie\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    243\u001b[0m                        return_inverse, return_counts)\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreturn_index\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mreshape_uniq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0muniq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreshape_uniq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Robie\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36mreshape_uniq\u001b[1;34m(uniq)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreshape_uniq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0muniq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muniq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[0muniq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muniq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0morig_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[0muniq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0muniq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "graphDistribs = [] # Not needed when we have the graphDistribsGlobal\n",
    "everyGraphProduced = np.unique(pg.generateGraphsGivenSetsOfArgs(posArgs, negArgs), axis=0)\n",
    "graphDistribsGlobal = []\n",
    "probDistribs = []\n",
    "argumentsInAgents = []\n",
    "polarities = []\n",
    "agentsStringified = []\n",
    "\n",
    "for agent in allAgents:\n",
    "    graphDistribsGlobalAgents = []\n",
    "    everyGraphProducedAgent = []\n",
    "    agPosArgs = agent[0]\n",
    "    agNegArgs = agent[1]\n",
    "    polarity = agent[2]\n",
    "    \n",
    "    argumentsInAgents.append([agPosArgs + agNegArgs])\n",
    "    polarities.append(polarity)\n",
    "    \n",
    "    agentsStringified.append(str(agent))\n",
    "    \n",
    "    # generate the plausible graphs for this agent\n",
    "    posArgsIdx = list(range(0,len(agPosArgs)))\n",
    "    negArgsIdx = list(range(len(agPosArgs), len(agPosArgs)+len(agNegArgs)))\n",
    "    x,y = pg.calculateProbabilityDistribution(posArgsIdx, negArgsIdx, polarity)\n",
    "    \n",
    "    # Generate an initial probability distribution for these graphs\n",
    "    initialProbDist = [1/len(x)] * len(x)\n",
    "    graphDistribs.append(x)\n",
    "    probDistribs.append(initialProbDist)\n",
    "    \n",
    "    # Convert the graphs into a global contribution, needed so that we can compare different agents of different sizes\n",
    "    noArgTypes = len(posArgs) + len(negArgs)\n",
    "    \n",
    "    \n",
    "    allAttacks = list(itertools.product(list(agPosArgs+agNegArgs), repeat=2))\n",
    "    allAttacksIdx = []\n",
    "    for attack in allAttacks:\n",
    "        ptn = ((attack[0]+1)*noArgTypes)- ((noArgTypes+1) - attack[1])+1\n",
    "        allAttacksIdx.append(ptn)\n",
    "    \n",
    "    for g in x:\n",
    "        #globalContribution = np.zeros(noArgTypes*noArgTypes)\n",
    "        globalContribution = np.full((noArgTypes*noArgTypes), np.inf)\n",
    "        globalContribution[allAttacksIdx] = g\n",
    "        graphDistribsGlobalAgents.append(globalContribution)\n",
    "    \n",
    "    graphDistribsGlobal.append(graphDistribsGlobalAgents)\n",
    "    \n",
    "    for g in y:\n",
    "        #globalContribution = np.zeros(noArgTypes*noArgTypes)\n",
    "        globalContribution = np.full((noArgTypes*noArgTypes), np.inf)\n",
    "        globalContribution[allAttacksIdx] = g\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 1 - No Enrichment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allProbDistribs = np.zeros((len(everyGraphProduced),len(graphDistribsGlobal)))\n",
    "\n",
    "for agentIdx, agentGraphs in enumerate(graphDistribsGlobal):\n",
    "    \n",
    "    probDistrib = [0]*len(everyGraphProduced)\n",
    "    \n",
    "    for graph in agentGraphs:\n",
    "        i = (np.where((everyGraphProduced == graph).all(axis=1)))[0][0]\n",
    "        allProbDistribs[i,agentIdx] = 1\n",
    "\n",
    "allProbDistribs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 2 - Higher Enrichment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkBiDirAttacks(graph):\n",
    "    \n",
    "    argsList = range(0,int((math.sqrt(len(graph)))))\n",
    "    dualLocations =  list(itertools.combinations(argsList, 2))\n",
    "    \n",
    "    for loc in dualLocations:\n",
    "\n",
    "        noOfArgs = int(math.sqrt(len(graph)))\n",
    "        pos = (loc[0] * noOfArgs) + loc[1]\n",
    "        counterPos = (loc[1] * noOfArgs) + loc[0]\n",
    "            \n",
    "        net = graph[pos] + graph[counterPos]\n",
    "        \n",
    "        if net == 2:\n",
    "            graph[pos] = 2\n",
    "            graph[counterPos] = 2\n",
    "        \n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allProbDistribs2 = np.zeros((len(everyGraphProduced),len(graphDistribsGlobal)))\n",
    "\n",
    "pnts = range(0, int(math.sqrt(len(everyGraphProduced[0]))))\n",
    "dualLocations = list(itertools.combinations(pnts, 2))\n",
    "\n",
    "for agentIdx, agentGraphs in enumerate(graphDistribsGlobal):\n",
    "    \n",
    "    probDistrib = [0]*len(everyGraphProduced)\n",
    "    \n",
    "    print('changing agent-----*******')\n",
    "    \n",
    "    for graph in agentGraphs:\n",
    "\n",
    "        for everyIdx, g in enumerate(everyGraphProduced):\n",
    "            \n",
    "            ginfs = np.sum(g == inf)\n",
    "            agentinfs = np.sum(graph == inf)\n",
    "            \n",
    "            # If the agent is same than he can enrich\n",
    "            if agentinfs == ginfs:\n",
    "                i = (np.where((everyGraphProduced == graph).all(axis=1)))[0][0]\n",
    "                allProbDistribs2[i,agentIdx] = 1\n",
    "            \n",
    "            # If the agent is smaller than he can enrich\n",
    "            if agentinfs > ginfs:\n",
    "                \n",
    "                x = checkBiDirAttacks(np.copy(graph))\n",
    "                y = checkBiDirAttacks(np.copy(g))\n",
    "                \n",
    "                multiple = x * y\n",
    "                np.isnan(multiple)\n",
    "                multiple[np.isnan(multiple)] = inf\n",
    "                multiple[np.where(multiple==4)] = multiple[np.where(multiple==4)] / 2\n",
    "                \n",
    "                print(y)\n",
    "                print(graph)\n",
    "                print('-----------------')\n",
    "                enrich = np.array_equal(multiple, graph)\n",
    "                if enrich:\n",
    "                    print(enrich)\n",
    "                    allProbDistribs2[everyIdx,agentIdx] = 1\n",
    "                \n",
    "print(allProbDistribs2)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 3 - Lower Enrichment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allProbDistribs3 = np.zeros((len(everyGraphProduced),len(graphDistribsGlobal)))\n",
    "\n",
    "pnts = range(0, int(math.sqrt(len(everyGraphProduced[0]))))\n",
    "dualLocations = list(itertools.combinations(pnts, 2))\n",
    "\n",
    "for agentIdx, agentGraphs in enumerate(graphDistribsGlobal):\n",
    "    \n",
    "    probDistrib = [0]*len(everyGraphProduced)\n",
    "    \n",
    "    print('changing agent-----*******')\n",
    "    \n",
    "    for graph in agentGraphs:\n",
    "\n",
    "        for everyIdx, g in enumerate(everyGraphProduced):\n",
    "            print(everyIdx, g)\n",
    "            \n",
    "            ginfs = np.sum(g == inf)\n",
    "            agentinfs = np.sum(graph == inf)\n",
    "            \n",
    "            # If the agent is same than he can enrich\n",
    "            if agentinfs == ginfs:\n",
    "                i = (np.where((everyGraphProduced == graph).all(axis=1)))[0][0]\n",
    "                print(i)\n",
    "                allProbDistribs3[i,agentIdx] = 1\n",
    "            \n",
    "            # If the agent is larger than he can enrich\n",
    "            if agentinfs < ginfs:\n",
    "                \n",
    "                x = checkBiDirAttacks(np.copy(graph))\n",
    "                y = checkBiDirAttacks(np.copy(g))\n",
    "                \n",
    "                multiple = x * y\n",
    "                np.isnan(multiple)\n",
    "                multiple[np.isnan(multiple)] = inf\n",
    "                multiple[np.where(multiple==4)] = multiple[np.where(multiple==4)] / 2\n",
    "                \n",
    "                print(y)\n",
    "                print(graph)\n",
    "                print('-----------------')\n",
    "                enrich = np.array_equal(multiple, y)\n",
    "                polarityMatch = (polarities[agentIdx] == pg.getGraphPolarityMixedGraphSize(g, posArgs, negArgs))\n",
    "                if enrich and polarityMatch:\n",
    "                    print(enrich)\n",
    "                    allProbDistribs3[everyIdx,agentIdx] = 1\n",
    "                \n",
    "print(allProbDistribs3)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 4 - Higher and Lower Enrichment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allProbDistribs4 = np.zeros((len(everyGraphProduced),len(graphDistribsGlobal)))\n",
    "\n",
    "pnts = range(0, int(math.sqrt(len(everyGraphProduced[0]))))\n",
    "dualLocations = list(itertools.combinations(pnts, 2))\n",
    "\n",
    "for agentIdx, agentGraphs in enumerate(graphDistribsGlobal):\n",
    "    \n",
    "    probDistrib = [0]*len(everyGraphProduced)\n",
    "    \n",
    "    print('changing agent-----*******')\n",
    "    \n",
    "    for graph in agentGraphs:\n",
    "\n",
    "        for everyIdx, g in enumerate(everyGraphProduced):\n",
    "            \n",
    "            ginfs = np.sum(g == inf)\n",
    "            agentinfs = np.sum(graph == inf)\n",
    "            \n",
    "            # If the agent is same than he can enrich\n",
    "            if agentinfs == ginfs:\n",
    "                i = (np.where((everyGraphProduced == graph).all(axis=1)))[0][0]\n",
    "                allProbDistribs4[i,agentIdx] = 1\n",
    "            \n",
    "            # If the agent is smaller than he can enrich\n",
    "            if agentinfs > ginfs:\n",
    "                \n",
    "                x = checkBiDirAttacks(np.copy(graph))\n",
    "                y = checkBiDirAttacks(np.copy(g))\n",
    "                \n",
    "                multiple = x * y\n",
    "                np.isnan(multiple)\n",
    "                multiple[np.isnan(multiple)] = inf\n",
    "                multiple[np.where(multiple==4)] = multiple[np.where(multiple==4)] / 2\n",
    "                \n",
    "                print(y)\n",
    "                print(graph)\n",
    "                print('------smaller agent------')\n",
    "                enrich = np.array_equal(multiple, graph)\n",
    "                if enrich:\n",
    "                    print(enrich)\n",
    "                    allProbDistribs4[everyIdx,agentIdx] = 1\n",
    "            \n",
    "            # If the agent is larger than he can enrich\n",
    "            if agentinfs < ginfs:\n",
    "                \n",
    "                x = checkBiDirAttacks(np.copy(graph))\n",
    "                y = checkBiDirAttacks(np.copy(g))\n",
    "                \n",
    "                multiple = x * y\n",
    "                np.isnan(multiple)\n",
    "                multiple[np.isnan(multiple)] = inf\n",
    "                multiple[np.where(multiple==4)] = multiple[np.where(multiple==4)] / 2\n",
    "                \n",
    "                print(y)\n",
    "                print(graph)\n",
    "                print('------larger agent-------')\n",
    "                enrich = np.array_equal(multiple, y)\n",
    "                polarityMatch = (polarities[agentIdx] == pg.getGraphPolarityMixedGraphSize(g, posArgs, negArgs))\n",
    "                if enrich and polarityMatch:\n",
    "                    print(enrich)\n",
    "                    allProbDistribs4[everyIdx,agentIdx] = 1\n",
    "                \n",
    "print(allProbDistribs4)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(allProbDistribs4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 5 - Enrichment the largest graph</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allProbDistribs5 = np.zeros((len(everyGraphProduced),len(graphDistribsGlobal)))\n",
    "\n",
    "pnts = range(0, int(math.sqrt(len(everyGraphProduced[0]))))\n",
    "dualLocations = list(itertools.combinations(pnts, 2))\n",
    "\n",
    "for agentIdx, agentGraphs in enumerate(graphDistribsGlobal):\n",
    "    \n",
    "    probDistrib = [0]*len(everyGraphProduced)\n",
    "    \n",
    "    print('changing agent-----*******')\n",
    "    \n",
    "    for graph in agentGraphs:\n",
    "\n",
    "        for everyIdx, g in enumerate(everyGraphProduced):\n",
    "            \n",
    "            ginfs = np.sum(g == inf)\n",
    "            agentinfs = np.sum(graph == inf)\n",
    "            \n",
    "            # If the agent is smaller than he can enrich\n",
    "            # we will check to see if the graph comparing too is the largest graph\n",
    "            if ginfs == 0:\n",
    "                \n",
    "                x = checkBiDirAttacks(np.copy(graph))\n",
    "                y = checkBiDirAttacks(np.copy(g))\n",
    "                \n",
    "                multiple = x * y\n",
    "                np.isnan(multiple)\n",
    "                multiple[np.isnan(multiple)] = inf\n",
    "                multiple[np.where(multiple==4)] = multiple[np.where(multiple==4)] / 2\n",
    "                \n",
    "                print(y)\n",
    "                print(graph)\n",
    "                print('-----------------')\n",
    "                enrich = np.array_equal(multiple, graph)\n",
    "                if enrich:\n",
    "                    print(enrich)\n",
    "                    allProbDistribs5[everyIdx,agentIdx] = 1\n",
    "                \n",
    "print(allProbDistribs5)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumallProbDistribs = allProbDistribs / (allProbDistribs != 0).sum(0)\n",
    "sumallProbDistribs2 = allProbDistribs2 / (allProbDistribs2 != 0).sum(0)\n",
    "sumallProbDistribs3 = allProbDistribs3 / (allProbDistribs3 != 0).sum(0)\n",
    "sumallProbDistribs4 = allProbDistribs4 / (allProbDistribs4 != 0).sum(0)\n",
    "sumallProbDistribs5 = allProbDistribs5 / (allProbDistribs5 != 0).sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = np.sum(sumallProbDistribs, axis=1) / len(allAgents)\n",
    "net2 = np.sum(sumallProbDistribs2, axis=1) / len(allAgents)\n",
    "net3 = np.sum(sumallProbDistribs3, axis=1) /  len(allAgents)\n",
    "net4 = np.sum(sumallProbDistribs4, axis=1) / len(allAgents)\n",
    "net5 = np.sum(sumallProbDistribs5, axis=1) / len(allAgents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(net4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['backend'] = \"Qt4Agg\"\n",
    "import pylab\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = range(0,len(net))  # 100 evenly-spaced values from 0 to 50\n",
    "\n",
    "\n",
    "pylab.plot(x, net)\n",
    "pylab.show()\n",
    "pylab.plot(x, net2)\n",
    "pylab.show()\n",
    "pylab.plot(x, net3)\n",
    "pylab.show()\n",
    "pylab.plot(x, net4)\n",
    "pylab.show()\n",
    "pylab.plot(x, net5)\n",
    "pylab.show()\n",
    "\n",
    "pylab.plot(x, net, label='approach1')\n",
    "pylab.plot(x, net2, label='approach2')\n",
    "pylab.plot(x, net3, label='approach3')\n",
    "pylab.plot(x, net4, label='approach4')\n",
    "pylab.plot(x, net5, label='approach5')\n",
    "pylab.legend()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Properties of Aggregation Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the following properties:\n",
    "\n",
    "<ol>\n",
    "<li>Identity</li>\n",
    "<li>Same set of agents produce same graph</li>\n",
    "<li>Order not important</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Query Agent</h1>\n",
    "<ul>\n",
    "<li>Some distributions don't give graphs for agents with more nodes than those in the training population</li>\n",
    "<li>Some distributions don't give graphs for agents with less nodes</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "Approaches to picking out a graph for our agents\n",
    "<ul>\n",
    "<li>We can restrict ourselves to graphs who have our nodes exactly\n",
    "<ul>\n",
    "<li>What if all those graphs have no mass on them, i.e. our training set doesn't contain similar agents?</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>We can use graphs who have at least one similar node in its grounded extension \n",
    "<ul>\n",
    "<li>We are travelling both up and down the graph</li>\n",
    "<li>This is a bit weird intuitively because we would never give lower graphs to an agent, because it would mean he would have to ignore one or more of his arguments to use such graphs</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>In our classifier experiment only concerned with predictive capacity so can look at polarities only</li>\n",
    "<li>In this case taking the approach of 'at least one arg in g.e' works fine</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "everyGraphProduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groundedExtensionsEveryGraph = []\n",
    "[groundedExtensionsEveryGraph.append(pg.getGroundedExtensionMixedGraphSize(thegraph, posArgs, negArgs)) for thegraph in everyGraphProduced]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allEveryGraphPols = []\n",
    "for g in groundedExtensionsEveryGraph:\n",
    "    if (list(g) == []):\n",
    "        allEveryGraphPols.append('n')\n",
    "        continue\n",
    "    if (set(g) <= set(posArgs)):\n",
    "        allEveryGraphPols.append('+')\n",
    "        continue\n",
    "    if (set(g) <=set(negArgs)):\n",
    "        allEveryGraphPols.append('-')\n",
    "        continue\n",
    "    else:\n",
    "        allEveryGraphPols.append(' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 1: Matching grounded extension</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(np.zeros((4, 5)))\n",
    "#d.set_index(['positiveChance','negativeChance', 'neutralChance', 'nothingChance'])\n",
    "d.index = ['positiveChance','negativeChance', 'neutralChance', 'nothingChance']\n",
    "d.columns = ['Apprch1','Apprch2', 'Apprch3', 'Apprch4', 'Apprch5']\n",
    "\n",
    "queryAgent = [1]\n",
    "\n",
    "groundedMatches = []\n",
    "\n",
    "for i, groundedExtensionsEveryGraphSingle in enumerate(groundedExtensionsEveryGraph):\n",
    "    \n",
    "    match = set(groundedExtensionsEveryGraphSingle).intersection(queryAgent)\n",
    "    if match:\n",
    "        groundedMatches.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allnets = [net, net2, net3, net4, net5]\n",
    "\n",
    "for netNo, n in enumerate(allnets):\n",
    "    groundedMatchesProbs = [n[i] for i in groundedMatches]\n",
    "    groundedMatchesSigns = [allEveryGraphPols[i] for i in groundedMatches]\n",
    "    \n",
    "    positiveChance = 0\n",
    "    negativeChance = 0\n",
    "    neutralChance = 0\n",
    "    nothingChance = 0\n",
    "\n",
    "    for i, sign in enumerate(groundedMatchesSigns):\n",
    "        if sign == '+':\n",
    "            positiveChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == '-':\n",
    "            negativeChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == 'n':\n",
    "            neutralChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        else:\n",
    "            nothingChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "            \n",
    "    d.iloc[:,netNo] = [positiveChance, negativeChance, neutralChance, nothingChance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 2: Exact Grounded Extension</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(np.zeros((4, 5)))\n",
    "#d.set_index(['positiveChance','negativeChance', 'neutralChance', 'nothingChance'])\n",
    "d.index = ['positiveChance','negativeChance', 'neutralChance', 'nothingChance']\n",
    "d.columns = ['Apprch1','Apprch2', 'Apprch3', 'Apprch4', 'Apprch5']\n",
    "\n",
    "queryAgent = [1]\n",
    "\n",
    "groundedMatches = []\n",
    "\n",
    "for i, groundedExtensionsEveryGraphSingle in enumerate(groundedExtensionsEveryGraph):\n",
    "    \n",
    "    match = set(groundedExtensionsEveryGraphSingle) == set(queryAgent)\n",
    "    if match:\n",
    "        groundedMatches.append(i)\n",
    "        \n",
    "print(groundedExtensionsEveryGraph)\n",
    "print(everyGraphProduced)\n",
    "groundedMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allnets = [net, net2, net3, net4, net5]\n",
    "\n",
    "for netNo, n in enumerate(allnets):\n",
    "    groundedMatchesProbs = [n[i] for i in groundedMatches]\n",
    "    groundedMatchesSigns = [allEveryGraphPols[i] for i in groundedMatches]\n",
    "    \n",
    "    positiveChance = 0\n",
    "    negativeChance = 0\n",
    "    neutralChance = 0\n",
    "    nothingChance = 0\n",
    "\n",
    "    for i, sign in enumerate(groundedMatchesSigns):\n",
    "        if sign == '+':\n",
    "            positiveChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == '-':\n",
    "            negativeChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == 'n':\n",
    "            neutralChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        else:\n",
    "            nothingChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "            \n",
    "    d.iloc[:,netNo] = [positiveChance, negativeChance, neutralChance, nothingChance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 3: Exact or Higher Grounded Extension</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(np.zeros((4, 5)))\n",
    "#d.set_index(['positiveChance','negativeChance', 'neutralChance', 'nothingChance'])\n",
    "d.index = ['positiveChance','negativeChance', 'neutralChance', 'nothingChance']\n",
    "d.columns = ['Apprch1','Apprch2', 'Apprch3', 'Apprch4', 'Apprch5']\n",
    "\n",
    "queryAgent = [1]\n",
    "\n",
    "groundedMatches = []\n",
    "\n",
    "for i, groundedExtensionsEveryGraphSingle in enumerate(groundedExtensionsEveryGraph):\n",
    "    match = set(queryAgent) <= set(groundedExtensionsEveryGraphSingle)\n",
    "    print('q:', queryAgent, 'g:', groundedExtensionsEveryGraphSingle, ' ',match)\n",
    "    if match:\n",
    "        groundedMatches.append(i)\n",
    "        \n",
    "groundedMatches\n",
    "groundedMatchesProbs = [n[i] for i in groundedMatches]\n",
    "print(groundedMatchesProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allnets = [net, net2, net3, net4, net5]\n",
    "\n",
    "for netNo, n in enumerate(allnets):\n",
    "    print(n)\n",
    "    groundedMatchesProbs = [n[i] for i in groundedMatches]\n",
    "    groundedMatchesSigns = [allEveryGraphPols[i] for i in groundedMatches]\n",
    "    \n",
    "    positiveChance = 0\n",
    "    negativeChance = 0\n",
    "    neutralChance = 0\n",
    "    nothingChance = 0\n",
    "\n",
    "    for i, sign in enumerate(groundedMatchesSigns):\n",
    "        if sign == '+':\n",
    "            positiveChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == '-':\n",
    "            negativeChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == 'n':\n",
    "            neutralChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        else:\n",
    "            nothingChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "            \n",
    "    d.iloc[:,netNo] = [positiveChance, negativeChance, neutralChance, nothingChance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Approach 4: Exact or Lower Grounded Extension</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(np.zeros((4, 5)))\n",
    "#d.set_index(['positiveChance','negativeChance', 'neutralChance', 'nothingChance'])\n",
    "d.index = ['positiveChance','negativeChance', 'neutralChance', 'nothingChance']\n",
    "d.columns = ['Apprch1','Apprch2', 'Apprch3', 'Apprch4', 'Apprch5']\n",
    "\n",
    "queryAgent = [1]\n",
    "\n",
    "groundedMatches = []\n",
    "\n",
    "for i, groundedExtensionsEveryGraphSingle in enumerate(groundedExtensionsEveryGraph):\n",
    "    \n",
    "    match = set(groundedExtensionsEveryGraphSingle) <= set(queryAgent)\n",
    "    if match:\n",
    "        groundedMatches.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allnets = [net, net2, net3, net4, net5]\n",
    "\n",
    "for netNo, n in enumerate(allnets):\n",
    "    groundedMatchesProbs = [n[i] for i in groundedMatches]\n",
    "    groundedMatchesSigns = [allEveryGraphPols[i] for i in groundedMatches]\n",
    "    \n",
    "    positiveChance = 0\n",
    "    negativeChance = 0\n",
    "    neutralChance = 0\n",
    "    nothingChance = 0\n",
    "\n",
    "    for i, sign in enumerate(groundedMatchesSigns):\n",
    "        if sign == '+':\n",
    "            positiveChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == '-':\n",
    "            negativeChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        if sign == 'n':\n",
    "            neutralChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "        else:\n",
    "            nothingChance += groundedMatchesProbs[i]\n",
    "            continue\n",
    "            \n",
    "    d.iloc[:,netNo] = [positiveChance, negativeChance, neutralChance, nothingChance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [2]\n",
    "b = [0,2]\n",
    "\n",
    "set(a) <= set(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
